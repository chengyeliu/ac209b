{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"CS109B Lab 4: Support Vector Machines\"\n",
    "output: \n",
    "  html_document:\n",
    "    theme: flatly\n",
    "    highlight: tango\n",
    "    toc: true\n",
    "    toc_float:\n",
    "      collapsed: true\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "Support Vector Machines in R\n",
    "============================\n",
    "\n",
    "There are two main implementations: `e1071::svm` provides an R\n",
    "interface to `libsvm`, and `kernlab::ksvm` provides a\n",
    "flexible implementation that can be extended at the R level. For the\n",
    "homework we recommend using the `e1071` implementation. In real life\n",
    "you should experiment and choose the approach you are most comfortable\n",
    "with. \n",
    "\n",
    "\n",
    "A simple first example\n",
    "======================\n",
    "\n",
    "The `iris` data is often used for classification examples, and is a\n",
    "good place to start given it's relative simplicity.\n",
    "\n",
    "\n",
    "Let's begin by classifying observations as `setosa` vs `other`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris2 <- transform(iris, Species = factor(Species == \"setosa\",\n",
    "                                          labels = c(\"other\", \"setosa\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, it's a good idea to start by plotting the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(ggplot2)\n",
    "library(GGally)\n",
    "\n",
    "ggpairs(iris2, mapping = aes(color = Species))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that `Species` separates pretty cleanly along different\n",
    "pairs of attributes. Let's start by considering just `Sepal.Width` and\n",
    "`Sepal.Length`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(iris2,\n",
    "       mapping = aes(x = Sepal.Width, y = Sepal.Length)) +\n",
    "    geom_point(mapping = aes(color = Species)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start with a simple linear kernel to help us build up an intuition\n",
    "for how SVM works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(e1071)\n",
    "\n",
    "m <- svm(Species ~ Sepal.Width + Sepal.Length,\n",
    "         data = iris2,\n",
    "         kernel = \"linear\")\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `svm` function returns a list of model statistics of class `svm`.\n",
    "There are a few methods available, including `plot` and `predict`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sapply(class(m), function(x) methods(class =x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `plot` methods gives us a visualization of the observed and\n",
    "predicted class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(m, iris2, formula = Sepal.Length ~ Sepal.Width)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also extract named components of the model to do our own\n",
    "plotting or other post-processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, we can augment our original scatter plot by \n",
    "highlighting the support vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris2$support.vector <- FALSE\n",
    "iris2$support.vector[m$index] <- TRUE\n",
    "\n",
    "ggplot(iris2,\n",
    "       mapping = aes(x = Sepal.Width,\n",
    "                     y = Sepal.Length,\n",
    "                     shape = Species,\n",
    "                     color = support.vector)) +\n",
    "    geom_point()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the predict method to create more interesting\n",
    "visualizations showing the decision boundary. For that \n",
    "we need to make predictions over the grid spanned by \n",
    "the observed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predGrid <- with(iris2,\n",
    "                 expand.grid(Sepal.Length = seq(min(Sepal.Length),\n",
    "                                                max(Sepal.Length),\n",
    "                                                length.out = 200),\n",
    "                             Sepal.Width = seq(min(Sepal.Width),\n",
    "                                               max(Sepal.Width),\n",
    "                                               length.out = 200)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next make predictions for each value in the grid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predGrid$predicted <- predict(m, predGrid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and plot the observed and predicted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p <- ggplot(predGrid,\n",
    "            mapping = aes(x = Sepal.Width,\n",
    "                          y = Sepal.Length)) +\n",
    "    geom_raster(mapping = aes(fill = predicted),\n",
    "                alpha = 0.2) +\n",
    "    geom_point(mapping = aes(shape = Species,\n",
    "                             color = support.vector),\n",
    "               data = iris2)\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the predict method to evaluate the classification \n",
    "accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table(iris2$Species, predict(m, iris2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cost parameter\n",
    "==================\n",
    "\n",
    "As we saw in the previous example, the decision boundary need not\n",
    "classify every observation correctly. The SVM algorithm actually\n",
    "selected a decision boundary that left one observation on the wrong\n",
    "side, despite the availability of decision boundaries that correctly\n",
    "classify all the points. This is because the boundary that correctly\n",
    "classifies all the points passes closer (on average) to other points\n",
    "in the support vector.\n",
    "\n",
    "We can adjust the cost of this constraint violation through the `cost`\n",
    "argument to the `svm` function. This allows us to trade off bias and\n",
    "variance to select a suitable decision boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## svm with high cost parameter\n",
    "m1 <- svm(Species ~ Sepal.Width + Sepal.Length,\n",
    "         data = iris2,\n",
    "         kernel = \"linear\",\n",
    "         cost = 20)\n",
    "\n",
    "## predictions on the grid established earlier\n",
    "predGrid$predicted1 <- predict(m1, predGrid)\n",
    "\n",
    "## plot\n",
    "p1 <- ggplot(predGrid,\n",
    "            mapping = aes(x = Sepal.Width, y = Sepal.Length)) +\n",
    "    geom_raster(mapping = aes(fill = predicted1),\n",
    "                alpha = 0.2) +\n",
    "    geom_point(mapping = aes(shape = Species, color = support.vector),\n",
    "               data = iris2)\n",
    "\n",
    "## comparison of predictions with different cost parameters\n",
    "p + ggtitle(\"Cost = 1 (default)\")\n",
    "p1 + ggtitle(\"Cost = 20\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By setting a high cost we're saying that we really want to avoid\n",
    "violating boundary constraints, even at the cost of leaving other\n",
    "points in the support vector closer to the decision boundary. We can\n",
    "think of this as fitting the model more closely to the data, at the\n",
    "possible expense of generalizability. \n",
    "\n",
    "\n",
    "A more complicated example\n",
    "==========================\n",
    "\n",
    "As the classification task becomes more complicated we will usually\n",
    "have to switch to a different kernel. Suppose now that we want to\n",
    "classify `versicolor` vs `other`, using `Petal.Length` and\n",
    "`Petal.Width`.\n",
    "\n",
    "A simple plot of the data reveals the problem we'll face:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris2 <- transform(iris,\n",
    "                   Species = factor(Species == \"versicolor\",\n",
    "                                    labels = c(\"other\", \"versicolor\")))\n",
    "\n",
    "ggplot(iris2,\n",
    "       mapping = aes(x = Petal.Width,\n",
    "                     y = Petal.Length,\n",
    "                     color = Species)) +\n",
    "    geom_point()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since `versicolor` is surrounded on both sides by `other`, we won't\n",
    "have much success with a linear kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2 <- svm(Species ~ Petal.Length + Petal.Width,\n",
    "          data = iris2,\n",
    "          kernel = \"linear\")\n",
    "plot(m2,\n",
    "     data = iris2,\n",
    "     formula = Petal.Width ~ Petal.Length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this type of classification we can switch to a `radial` kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m3 <- svm(Species ~ Petal.Width + Petal.Length,\n",
    "         data = iris2,\n",
    "         kernel = \"radial\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The radial kernel gives much better classification in this scenario:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris2$support.vector <- FALSE\n",
    "iris2$support.vector[m3$index] <- TRUE\n",
    "\n",
    "predGrid <- with(iris2,\n",
    "                 expand.grid(Petal.Length = seq(min(Petal.Length),\n",
    "                                                max(Petal.Length),\n",
    "                                                length.out = 200),\n",
    "                             Petal.Width = seq(min(Petal.Width),\n",
    "                                               max(Petal.Width),\n",
    "                                               length.out = 200)))\n",
    "predGrid$predicted <- predict(m3, predGrid)\n",
    "\n",
    "p <- ggplot(predGrid,\n",
    "            mapping = aes(x = Petal.Width,\n",
    "                          y = Petal.Length)) +\n",
    "    geom_raster(mapping = aes(fill = predicted),\n",
    "                alpha = 0.2) +\n",
    "    geom_point(mapping = aes(shape = Species,\n",
    "                             color = support.vector),\n",
    "               data = iris2)\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gamma parameter\n",
    "===================\n",
    "\n",
    "For non-linear kernels (such as radial) the bias-variance trade-off\n",
    "can be controlled both by the `cost` parameter (as with linear\n",
    "kernels) and by the `gamma` parameter (there is no gamma for a linear\n",
    "kernel). The kernel maps the observed features to a higher-dimensional\n",
    "feature space; the `gamma` parameter controls the \"smoothness\" of that mapping.\n",
    "\n",
    "We can see the effect of the `gamma` parameter by varying the value and\n",
    "plotting the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SVM with gamma = 0.1\n",
    "m4 <- svm(Species ~ Petal.Width + Petal.Length,\n",
    "         data = iris2,\n",
    "         kernel = \"radial\",\n",
    "         gamma = 0.1)\n",
    "## SVM with gamma = 10\n",
    "m5 <- svm(Species ~ Petal.Width + Petal.Length,\n",
    "         data = iris2,\n",
    "         kernel = \"radial\",\n",
    "         gamma = 10)\n",
    "\n",
    "## identify support vectors\n",
    "iris2$support.vector1 <- FALSE\n",
    "iris2$support.vector1[m4$index] <- TRUE\n",
    "iris2$support.vector2 <- FALSE\n",
    "iris2$support.vector2[m5$index] <- TRUE\n",
    "\n",
    "## make predictions on the grid\n",
    "predGrid$predicted1 <- predict(m4, predGrid)\n",
    "predGrid$predicted2 <- predict(m5, predGrid)\n",
    "\n",
    "## graph observed and predicted values for each gamma value\n",
    "p1 <- ggplot(predGrid,\n",
    "             mapping = aes(x = Petal.Width,\n",
    "                           y = Petal.Length)) +\n",
    "    geom_raster(mapping = aes(fill = predicted1),\n",
    "                alpha = 0.2) +\n",
    "    geom_point(mapping = aes(shape = Species,\n",
    "                             color = support.vector1),\n",
    "               data = iris2)\n",
    "\n",
    "p2 <- ggplot(predGrid,\n",
    "             mapping = aes(x = Petal.Width,\n",
    "                           y = Petal.Length)) +\n",
    "    geom_raster(mapping = aes(fill = predicted2),\n",
    "                alpha = 0.2) +\n",
    "    geom_point(mapping = aes(shape = Species,\n",
    "                             color = support.vector2),\n",
    "               data = iris2)\n",
    "\n",
    "\n",
    "p1 + ggtitle(\"Gamma = 0.1\")\n",
    "p + ggtitle(\"Default gamma = 1/ncol(x)\")\n",
    "p2 + ggtitle(\"Gama = 10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuning cost and gamma\n",
    "=====================\n",
    "\n",
    "We've seen that we can trade off bias and variance via the `cost` and\n",
    "(for non-linear kernels) `gamma`. But what parameter values should we\n",
    "choose?\n",
    "\n",
    "The `e1071` package provides a `tune` function that can be used to\n",
    "select appropriate parameters via cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp.tune <- tune(svm,\n",
    "                Species ~ Petal.Width + Petal.Length,\n",
    "                data = iris2,\n",
    "                ## NOTE: better to try more combinations,\n",
    "                ## limited here to avoid long computation time\n",
    "                ranges = list(gamma = seq(2, 30, by = 2), \n",
    "                              cost = seq(2, 30, by = 2)))\n",
    "\n",
    "sp.tune                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a`plot` method that you can use to visualize the\n",
    "performance of your SVM as a function of the tuning parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(sp.tune)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "but I don't really like that way of visualizing performance. \n",
    "Better to do the plotting yourself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names(sp.tune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(sp.tune$performances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(sp.tune$performances, \n",
    "       mapping = aes(x = gamma, y = error)) + \n",
    "  geom_line() + \n",
    "  facet_wrap(~cost, labeller = label_both)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `tune` function also returns the best model (among other things).\n",
    "We can use the `best.model` component to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## identify support vectors\n",
    "iris2$support.vector <- FALSE\n",
    "iris2$support.vector[sp.tune$best.model$index] <- TRUE\n",
    "\n",
    "## predict using the grid established earlier\n",
    "predGrid$predicted <- predict(sp.tune$best.model, predGrid)\n",
    "\n",
    "## plot\n",
    "p <- ggplot(predGrid,\n",
    "            mapping = aes(x = Petal.Width,\n",
    "                          y = Petal.Length)) +\n",
    "    geom_raster(mapping = aes(fill = predicted),\n",
    "                alpha = 0.2) +\n",
    "    geom_point(mapping = aes(shape = Species,\n",
    "                             color = support.vector),\n",
    "               data = iris2)\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note When selecting parameter values via cross-validation you\n",
    "should generally hold out a test set to calculate the accuracy of the\n",
    "best model identified through cross-validation on the training set. In\n",
    "these `iris` examples we skipped that step in the interest of focusing\n",
    "on the mechanics of SVM in R.*\n",
    "\n",
    "More predictors and classes\n",
    "===========================\n",
    "\n",
    "In the examples thus far we've classified only a single binary\n",
    "response, using only two features as predictors. \n",
    "\n",
    "More than two features\n",
    "----------------------\n",
    "\n",
    "Using only two features made it easy to understand what the algorithm\n",
    "does, especially because constructing graphs of the decision boundary\n",
    "is easy in the two-predictor case. However, SVM is by no means limited\n",
    "to two observed features, and indeed using more features will\n",
    "generally improve your classification accuracy. From a practical \n",
    "standpoint there is nothing much to it -- just add the additional \n",
    "features to the right-hand-side of the formula argument to `svm`.\n",
    "\n",
    "More than two response categories\n",
    "---------------------------------\n",
    "\n",
    "SVM does not generalize to more than two response categories. In\n",
    "practice this isn't a huge drawback -- we simply use multiple SVMs,\n",
    "each one making a binary classification. This is handled transparently\n",
    "by the `svm` function.\n",
    "\n",
    "Multiple class multiple feature example\n",
    "---------------------------------------\n",
    "\n",
    "Again, from a mechanical perspective not much changes when classifying\n",
    "k>2 response categories using more than two features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m6 <- svm(Species ~ .,\n",
    "          data = iris)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict works just as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table(iris$Species, predict(m6, data = iris))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our graphical displays are limited to two dimensions we do need\n",
    "to take more care when graphing the predictions. \n",
    "\n",
    "*Note that the graph below is somewhat more complicated than I would \n",
    "expect you to do -- the purpose of the code below is to try to give \n",
    "you some insight into what happens when we have more than two response \n",
    "levels and features.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### establish a grid of prediction grids ###\n",
    "\n",
    "iris2 <- iris\n",
    "\n",
    "## calculate cut points for each grid\n",
    "slh <- hist(iris2$Sepal.Length, 4, plot = FALSE)\n",
    "swh <- hist(iris2$Sepal.Width, 4, plot = FALSE)\n",
    "\n",
    "iris2$Sepal.Length <- as.numeric(as.character(cut(iris2$Sepal.Length,\n",
    "                                                  breaks = slh$breaks,\n",
    "                                                  labels = slh$mids,\n",
    "                                                  include.lowest = TRUE)))\n",
    "iris2$Sepal.Width <- as.numeric(as.character(cut(iris2$Sepal.Width,\n",
    "                                                 breaks = swh$breaks,\n",
    "                                                 labels = swh$mids,\n",
    "                                                 include.lowest = TRUE)))\n",
    "\n",
    "## construct the grid of prediction grids\n",
    "predGrid <- with(iris2,\n",
    "                 expand.grid(Petal.Length = seq(min(Petal.Length), \n",
    "                                                max(Petal.Length), \n",
    "                                                length.out = 20),\n",
    "                             Petal.Width = seq(min(Petal.Width), \n",
    "                                               max(Petal.Width), \n",
    "                                               length.out = 20),\n",
    "                             Sepal.Length = unique(Sepal.Length),\n",
    "                             Sepal.Width = unique(Sepal.Width)))\n",
    "\n",
    "### make predictions ###\n",
    "predGrid$predicted <- predict(m6, predGrid)\n",
    "\n",
    "### plot petal width vs petal length for each sepal length X width grid ###\n",
    "p <- ggplot(predGrid,\n",
    "            mapping = aes(x = Petal.Width, y = Petal.Length)) +\n",
    "    geom_raster(mapping = aes(fill = predicted),\n",
    "                alpha = 0.2) +\n",
    "    geom_point(mapping = aes(color = Species),\n",
    "               data = iris2) +\n",
    "    facet_grid(Sepal.Length ~ Sepal.Width, labeller = label_both)\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your turn: Detecting forgeries\n",
    "============================\n",
    "\n",
    "The UC Irvine Machine Learning Repository contains a wealth of\n",
    "interesting data sets. The data at\n",
    "<https://archive.ics.uci.edu/ml/machine-learning-databases/00267/data_banknote_authentication.txt>\n",
    "contains data about the properties of images of real and counterfeit\n",
    "bank notes. \n",
    "\n",
    "Some documentation is available\n",
    "at <https://archive.ics.uci.edu/ml/datasets/banknote+authentication#>.\n",
    "Note that there are not headers in the data file: the column names are\n",
    "\"variance\", \"skew\", \"curtosis\", \"entropy\", and \"class\".\n",
    "\n",
    "Unfortunately the documentation is a bit sparse -- for now let's\n",
    "assume that `class == 0` is real and `class == 1` counterfeit,\n",
    "although it could be vice versa. \n",
    "\n",
    "Our goal is to classify these images as real or counterfeit.\n",
    "\n",
    "1. Read the data into R. Ensure that the columns are named correctly\n",
    "   and that `class` is a factor.\n",
    "\n",
    "2. Split the data into train and test sets.\n",
    "\n",
    "3. Visually examine the associations among the features by class.\n",
    "\n",
    "4. Predict `class` using only `skew` and `entropy`. \n",
    "  * Plot `skew` vs `entropy`, coloring by `class`. Based on this\n",
    "    visualization, what kernel will you use in your SVM?\n",
    "    \n",
    "  * Use the `svm` function to classify banknotes in the training set.\n",
    "\n",
    "  * Plot the actual and predicted class in the test data\n",
    "\n",
    "  * Generate a confusion matrix using the test data as the criterion.\n",
    "  \n",
    "5. Classify banknotes using all available information.\n",
    "\n",
    "   * Use the `tune` function select optimal `cost` and `gamma`\n",
    "parameter values (use all the available features).\n",
    "\n",
    "   * Generate a confusion matrix using the test data as the criterion."
   ]
  }
 ],
 "metadata": {
        "kernelspec": {
            "display_name": "R",
            "language": "R",
            "name": "ir"
        },
        "language_info": {
            "codemirror_mode": "r",
            "file_extension": ".r",
            "mimetype": "text/x-r-source",
            "name": "R",
            "pygments_lexer": "r",
            "version": "3.2.3"
        }
    },
 "nbformat": 4,
 "nbformat_minor": 2
}
